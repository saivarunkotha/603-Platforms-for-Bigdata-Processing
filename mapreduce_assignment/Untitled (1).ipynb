{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa5a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date of birth is 2nd June 2001\n",
    "#Birth month is 6. So choosing Harry Potter and the Half Blood Prince\n",
    "# birth date is 2 so choosing the pages 2-11 in the book \n",
    "# Created the .txt based on the above conditions and saved as file1.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da237b3",
   "metadata": {},
   "source": [
    "# Python code and use MapReduct to count occurrences of each word in the first text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ce735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(as:1\n",
      "(the:1\n",
      "?”:2\n",
      "a:43\n",
      "about:3\n",
      "above:1\n",
      "accusations,:1\n",
      "act:1\n",
      "actually:1\n",
      "affect:1\n",
      "afraid:2\n",
      "after:2\n",
      "again.:1\n",
      "again.”:1\n",
      "against:2\n",
      "alarm,:1\n",
      "alarming:1\n",
      "all:2\n",
      "all,:1\n",
      "all.:1\n",
      "allowed:1\n",
      "alone:1\n",
      "already:1\n",
      "also:1\n",
      "an:1\n",
      "and:39\n",
      "announcing:1\n",
      "answer:1\n",
      "antique:1\n",
      "any:1\n",
      "anybody:1\n",
      "anybody?”:1\n",
      "anyone:2\n",
      "apart:1\n",
      "appearances,:1\n",
      "appeared:1\n",
      "appreciate:1\n",
      "are:1\n",
      "arms:1\n",
      "around:1\n",
      "arrange:1\n",
      "arranged:1\n",
      "arrive:1\n",
      "as:13\n",
      "ash:1\n",
      "asked:1\n",
      "at:13\n",
      "back:3\n",
      "bad:3\n",
      "balder,:1\n",
      "barely:2\n",
      "be:2\n",
      "been:8\n",
      "before,:1\n",
      "before.:1\n",
      "begin,”:1\n",
      "behavior:1\n",
      "behind:2\n",
      "being:2\n",
      "believe:1\n",
      "below.:1\n",
      "beneath:1\n",
      "best:2\n",
      "betray:1\n",
      "better:1\n",
      "bleated:1\n",
      "blood:6\n",
      "boded:1\n",
      "bones:1\n",
      "both:1\n",
      "bother:2\n",
      "bounced:1\n",
      "bowler:2\n",
      "braver:1\n",
      "breathlessly,:1\n",
      "bridge:3\n",
      "bridges.:1\n",
      "brief:1\n",
      "briefly:1\n",
      "bright:1\n",
      "broad:1\n",
      "brockdale:1\n",
      "broomsticks:1\n",
      "brought:1\n",
      "brushing:1\n",
      "burst:1\n",
      "but:2\n",
      "by:3\n",
      "call,:1\n",
      "call.:1\n",
      "campaign:1\n",
      "campaign.:1\n",
      "can:2\n",
      "careworn.:1\n",
      "cars:1\n",
      "caused:2\n",
      "chair,:1\n",
      "chairs:1\n",
      "chewing:1\n",
      "chill.:1\n",
      "chilly:1\n",
      "chorley,:1\n",
      "chortling,:1\n",
      "chosen:1\n",
      "cleanly:1\n",
      "climbed:1\n",
      "cloak,:1\n",
      "closed:1\n",
      "clutching:1\n",
      "collapsing?:1\n",
      "coming:1\n",
      "community:1\n",
      "compliment,:1\n",
      "concealing:1\n",
      "concluded,:1\n",
      "control:1\n",
      "convey:1\n",
      "convince:1\n",
      "cornelius:1\n",
      "corner:2\n",
      "cough:3\n",
      "cough.:1\n",
      "could:1\n",
      "country:2\n",
      "country,”:1\n",
      "course:1\n",
      "course,:1\n",
      "course,”:1\n",
      "crisp,:1\n",
      "crumpled:1\n",
      "damage:1\n",
      "dare:2\n",
      "dark:1\n",
      "day,”:1\n",
      "day.:1\n",
      "dear:1\n",
      "decisive:1\n",
      "depicted:1\n",
      "depths:1\n",
      "desk:1\n",
      "desk,:1\n",
      "desk.:1\n",
      "desperate:1\n",
      "did:2\n",
      "difficult:1\n",
      "dirty:1\n",
      "dislike:1\n",
      "dismal;:1\n",
      "distinctly:1\n",
      "down,:1\n",
      "downright:1\n",
      "dozen:1\n",
      "dragon:1\n",
      "dreaming:1\n",
      "during:1\n",
      "dying:1\n",
      "each:1\n",
      "earth:1\n",
      "election:2\n",
      "emerald:1\n",
      "empty:2\n",
      "encompassed:1\n",
      "encounter:1\n",
      "end,:1\n",
      "enough:2\n",
      "er:1\n",
      "even:1\n",
      "evening:1\n",
      "ever:1\n",
      "every:1\n",
      "everything:1\n",
      "experts:1\n",
      "explain:2\n",
      "explanation:1\n",
      "expression,:1\n",
      "extra:1\n",
      "eyes:1\n",
      "face:3\n",
      "facing:1\n",
      "fair:1\n",
      "family?:1\n",
      "far:1\n",
      "fast:1\n",
      "fatherly:1\n",
      "fault:1\n",
      "fault.:1\n",
      "feel:1\n",
      "felt:2\n",
      "felt.:1\n",
      "fewer:1\n",
      "find:3\n",
      "fine:2\n",
      "fireplace:2\n",
      "fireplace,:1\n",
      "firmly:1\n",
      "first:3\n",
      "fixed:1\n",
      "flames:1\n",
      "flames,:2\n",
      "flicker:1\n",
      "for:10\n",
      "foreseen:1\n",
      "forget:1\n",
      "former:1\n",
      "forward:1\n",
      "found:1\n",
      "freak:1\n",
      "froglike:1\n",
      "from:8\n",
      "front:1\n",
      "froze,:1\n",
      "fudge:8\n",
      "fudge,:6\n",
      "fudge.:1\n",
      "fudge.”:3\n",
      "fudge’s:3\n",
      "furthermore,:1\n",
      "gave:1\n",
      "generally:1\n",
      "gently.:1\n",
      "gerbil.:1\n",
      "gesturing:1\n",
      "getting:1\n",
      "glass.:2\n",
      "go:1\n",
      "going:4\n",
      "good:1\n",
      "got:1\n",
      "government:2\n",
      "government’s:1\n",
      "grate:1\n",
      "grayer,:1\n",
      "green:2\n",
      "grim:1\n",
      "grin.:1\n",
      "gripped:1\n",
      "grueling:1\n",
      "had:33\n",
      "half:6\n",
      "hallucination:1\n",
      "hand:2\n",
      "hand.:2\n",
      "handsome:1\n",
      "hardest:1\n",
      "harry:6\n",
      "has:2\n",
      "hasn’t:1\n",
      "hat:1\n",
      "haunt:1\n",
      "have:3\n",
      "have,:1\n",
      "having:1\n",
      "he:41\n",
      "head:2\n",
      "hear:1\n",
      "heard:3\n",
      "heart:1\n",
      "help:1\n",
      "helpings:1\n",
      "herbert:1\n",
      "herself:1\n",
      "hesitated:1\n",
      "him:3\n",
      "him,:3\n",
      "him-:1\n",
      "him.:2\n",
      "him?:1\n",
      "himself:2\n",
      "himself.:1\n",
      "himself;:1\n",
      "his:37\n",
      "hoax:1\n",
      "hoax,:1\n",
      "honestly:1\n",
      "hope:1\n",
      "hope.:1\n",
      "hoped:1\n",
      "hoping:2\n",
      "how:4\n",
      "however,:1\n",
      "hurricane:1\n",
      "hurried:1\n",
      "i:6\n",
      "if:1\n",
      "ignorant:1\n",
      "immediately:1\n",
      "immediately.:1\n",
      "impossible:1\n",
      "in:21\n",
      "indeed:1\n",
      "inquiringly:1\n",
      "inside:1\n",
      "instead,”:1\n",
      "into:6\n",
      "introduce:1\n",
      "involved:1\n",
      "it:24\n",
      "itself:1\n",
      "it’s:2\n",
      "i’ll:2\n",
      "i’m:3\n",
      "j.k.:6\n",
      "jacket.:1\n",
      "job:1\n",
      "job.:1\n",
      "july.:1\n",
      "junior:1\n",
      "just:1\n",
      "keeping:1\n",
      "kind:1\n",
      "kindly:2\n",
      "knees.:1\n",
      "knew:2\n",
      "know:1\n",
      "known:1\n",
      "lack:2\n",
      "last:1\n",
      "last,:1\n",
      "last.:1\n",
      "later,:1\n",
      "laughed.:1\n",
      "let:1\n",
      "life:1\n",
      "like:3\n",
      "likely:1\n",
      "lime-green:1\n",
      "little:4\n",
      "live:1\n",
      "live.:1\n",
      "lived,:1\n",
      "living:2\n",
      "long:5\n",
      "longer:1\n",
      "look:1\n",
      "look.:2\n",
      "look.”:1\n",
      "looked:2\n",
      "looking:3\n",
      "loss:1\n",
      "lot:2\n",
      "mad.:1\n",
      "made:2\n",
      "magic:3\n",
      "maintain:1\n",
      "man:3\n",
      "man.:1\n",
      "mantelpiece.:1\n",
      "many:1\n",
      "marble:2\n",
      "me:4\n",
      "me.:1\n",
      "mean:1\n",
      "meant:1\n",
      "meet.:1\n",
      "meeting:1\n",
      "memo,:1\n",
      "mention:2\n",
      "middle:1\n",
      "minister:19\n",
      "minister,:3\n",
      "minister,”:1\n",
      "minister.:5\n",
      "ministers,:1\n",
      "minister’s:3\n",
      "ministry:1\n",
      "miserable:1\n",
      "mist:2\n",
      "moment:1\n",
      "mood:1\n",
      "more:2\n",
      "morosely:1\n",
      "motionless,:1\n",
      "mournfully.:1\n",
      "moved:1\n",
      "mr.:1\n",
      "much:2\n",
      "much.:1\n",
      "muggle:1\n",
      "muggles:1\n",
      "muggles.:1\n",
      "murders:1\n",
      "murders?:1\n",
      "must:1\n",
      "muttered:1\n",
      "nasty:1\n",
      "naturally,:1\n",
      "needed:1\n",
      "neither:1\n",
      "never:2\n",
      "never,:1\n",
      "news.:1\n",
      "next:1\n",
      "night:1\n",
      "nobody:2\n",
      "non-magical:2\n",
      "nor:1\n",
      "normal.:1\n",
      "nose:2\n",
      "not:9\n",
      "not.:1\n",
      "nothing:2\n",
      "now:1\n",
      "occasional:1\n",
      "odds-on:1\n",
      "of:33\n",
      "off.:1\n",
      "office:1\n",
      "office,:1\n",
      "oh:1\n",
      "oil:1\n",
      "old,:1\n",
      "on:8\n",
      "on,:1\n",
      "on?”:1\n",
      "once,:1\n",
      "once.:1\n",
      "one:3\n",
      "only:2\n",
      "onto:1\n",
      "opponent:1\n",
      "opposition.”:1\n",
      "or:3\n",
      "otherwise,:1\n",
      "our:1\n",
      "out:4\n",
      "outrageous:1\n",
      "outstretched.:1\n",
      "over:3\n",
      "own:2\n",
      "page:1\n",
      "page|2:1\n",
      "page|3:1\n",
      "page|4:1\n",
      "page|5:1\n",
      "page|6:1\n",
      "page|7:1\n",
      "painting:2\n",
      "patted:1\n",
      "peculiarly:1\n",
      "people:3\n",
      "perfectly:1\n",
      "pin-striped:1\n",
      "placing:1\n",
      "planned:1\n",
      "plate:1\n",
      "pleased:1\n",
      "point).:1\n",
      "poking:1\n",
      "policemen:1\n",
      "politicians:1\n",
      "population:2\n",
      "population,:1\n",
      "portly:1\n",
      "portrait:3\n",
      "potter:6\n",
      "powder:1\n",
      "precisely:1\n",
      "predecessor.:1\n",
      "prepared:1\n",
      "president:2\n",
      "pressing:1\n",
      "prevented:1\n",
      "prime:29\n",
      "prince:6\n",
      "property?:1\n",
      "pulling:1\n",
      "pulse:1\n",
      "quickened:1\n",
      "quite:2\n",
      "rather:3\n",
      "reading:1\n",
      "realized:2\n",
      "really:3\n",
      "rearranged,”:1\n",
      "reassurances:1\n",
      "reflection:1\n",
      "regulations:1\n",
      "relaxed:1\n",
      "remained:1\n",
      "remembered:2\n",
      "reminding):1\n",
      "remotely:1\n",
      "respond:2\n",
      "responded:1\n",
      "responsibility:1\n",
      "responsible:1\n",
      "resulted:1\n",
      "resumed:1\n",
      "return:1\n",
      "reveals:1\n",
      "right,:1\n",
      "river:1\n",
      "room,:2\n",
      "room.:2\n",
      "rowling:6\n",
      "rubbing:1\n",
      "ruckus:1\n",
      "rug,:1\n",
      "said:11\n",
      "said,:3\n",
      "said.:1\n",
      "same:1\n",
      "sank.:1\n",
      "sash:1\n",
      "savoring:1\n",
      "saw:1\n",
      "say,:2\n",
      "say.:1\n",
      "scared-looking:1\n",
      "scheming,:1\n",
      "schoolboy.:1\n",
      "seat,:1\n",
      "second:1\n",
      "seconds:1\n",
      "secrecy.”:1\n",
      "secret:1\n",
      "see:5\n",
      "seem:1\n",
      "seen:1\n",
      "self-proclaimed:1\n",
      "sending:1\n",
      "serious:1\n",
      "shaken:1\n",
      "shaking:1\n",
      "shall:1\n",
      "shiver,:1\n",
      "shock:1\n",
      "should:2\n",
      "shoulder:1\n",
      "silver:1\n",
      "sincerely,:1\n",
      "sitting:1\n",
      "sleep:1\n",
      "sleeves:1\n",
      "slight:1\n",
      "slowly:1\n",
      "small,:1\n",
      "snapped:1\n",
      "so:5\n",
      "soft:1\n",
      "some:3\n",
      "somehow:1\n",
      "something:2\n",
      "sort:2\n",
      "soul,:1\n",
      "sound:1\n",
      "sound.:1\n",
      "sounded:1\n",
      "speak:1\n",
      "speech,:1\n",
      "speechless:1\n",
      "spending:2\n",
      "spinning:1\n",
      "standing:1\n",
      "statement.:1\n",
      "stepped:1\n",
      "stern:1\n",
      "stiffly,:1\n",
      "still:2\n",
      "still-dumbstruck:1\n",
      "stood:2\n",
      "stopped:1\n",
      "straightening:1\n",
      "strain:1\n",
      "stretching:1\n",
      "striding:1\n",
      "suggest:2\n",
      "support:1\n",
      "supposed:1\n",
      "surprise:1\n",
      "taken:1\n",
      "taking:1\n",
      "talking:2\n",
      "teacup:2\n",
      "telephone:2\n",
      "tell:1\n",
      "ten:1\n",
      "terrified:1\n",
      "than:4\n",
      "that:26\n",
      "that.:1\n",
      "that’s:1\n",
      "the:100\n",
      "them:2\n",
      "them.:1\n",
      "themselves,:1\n",
      "then:1\n",
      "then,:1\n",
      "then,”:1\n",
      "then?”:1\n",
      "there:1\n",
      "there,:1\n",
      "there’s:1\n",
      "these:1\n",
      "they:3\n",
      "they?”:1\n",
      "thin:1\n",
      "things,:1\n",
      "thinner,:1\n",
      "this:11\n",
      "this,:2\n",
      "those:3\n",
      "though:4\n",
      "thought:3\n",
      "throughout:1\n",
      "throw:1\n",
      "thrown:1\n",
      "tie:1\n",
      "time:2\n",
      "time,:1\n",
      "to:45\n",
      "told:1\n",
      "tomorrow:1\n",
      "tonight,:1\n",
      "too,:1\n",
      "took:1\n",
      "top.:1\n",
      "toward:1\n",
      "tried:2\n",
      "triumph:1\n",
      "true.:2\n",
      "trying:2\n",
      "turned:4\n",
      "two:1\n",
      "two,:1\n",
      "ugly:1\n",
      "under:1\n",
      "unfazed:1\n",
      "unfortunately,:1\n",
      "unseasonable:1\n",
      "until:1\n",
      "up:3\n",
      "upon:1\n",
      "urgent:1\n",
      "use:1\n",
      "usual.:1\n",
      "utterly:1\n",
      "vain:1\n",
      "vance:1\n",
      "vanished:1\n",
      "very:10\n",
      "visits:1\n",
      "voice:3\n",
      "waiting:1\n",
      "wand:1\n",
      "warned:1\n",
      "was:25\n",
      "was,:2\n",
      "wasn’t:2\n",
      "watched,:1\n",
      "watching:1\n",
      "watery:1\n",
      "way:1\n",
      "way.:1\n",
      "we:1\n",
      "weakly.:1\n",
      "wear:1\n",
      "wearily:1\n",
      "wearing:1\n",
      "weather:1\n",
      "week:4\n",
      "week,:1\n",
      "well,”:1\n",
      "well-publicized:1\n",
      "well.:1\n",
      "went:1\n",
      "went.:1\n",
      "were:9\n",
      "were,”:1\n",
      "west:2\n",
      "what:2\n",
      "what’s:1\n",
      "when:3\n",
      "where:1\n",
      "while:1\n",
      "who:2\n",
      "whole:1\n",
      "whooshing:1\n",
      "whose:1\n",
      "why:4\n",
      "wide:1\n",
      "wig:1\n",
      "will:1\n",
      "wind:1\n",
      "window,:2\n",
      "windows,:1\n",
      "witches:1\n",
      "with:9\n",
      "within:1\n",
      "without:1\n",
      "wizard:1\n",
      "wizarding:1\n",
      "wizards:1\n",
      "world:2\n",
      "worry,”:1\n",
      "would:4\n",
      "www.ztcprep.com:10\n",
      "years:2\n",
      "yesterday:1\n",
      "you:5\n",
      "you?”:2\n",
      "your:3\n",
      "you’ll:1\n",
      "you’re:2\n",
      "you’ve:1\n",
      "–:6\n",
      "—:12\n",
      "—”:2\n",
      "“a:1\n",
      "“ah:1\n",
      "“but:3\n",
      "“but,”:1\n",
      "“difficult:1\n",
      "“er,”:1\n",
      "“good:1\n",
      "“had:1\n",
      "“hello?”:1\n",
      "“how:1\n",
      "“i:2\n",
      "“it’s:1\n",
      "“i’ve:1\n",
      "“kindly:1\n",
      "“listen.:1\n",
      "“my:1\n",
      "“no,:1\n",
      "“no,”:1\n",
      "“not:1\n",
      "“of:1\n",
      "“surely:1\n",
      "“that:1\n",
      "“the:1\n",
      "“to:1\n",
      "“we:2\n",
      "“what:1\n",
      "“why:1\n",
      "“yes,:2\n",
      "“you:1\n",
      "“you’re:1\n",
      "…:10\n",
      "…”:3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mapreduce(file1_path):\n",
    "    #defing a variable to keep track of word counts\n",
    "    wordcounts={}\n",
    "    #access the contents from the file1 with using open method in python\n",
    "    with open (file1_path,'r',encoding= 'utf-8') as f1:\n",
    "        #fetching line by line from the file\n",
    "        for line in f1:\n",
    "            #passing the lines to the map function\n",
    "            mapp=mapfunction(line)\n",
    "            #using the reduce function getting th number of times each word occurs. \n",
    "            wordcounts=reducefunction(wordcounts,mapp)\n",
    "    #rreturning the Dictionary wordcounts\n",
    "    return wordcounts\n",
    "#defining the mapfunction\n",
    "def mapfunction(line):\n",
    "    #creating the count dictionary as to generate the key-value pairs\n",
    "    count={}\n",
    "    #removing the white spaces at the beginning and end of the lines using the strip function.\n",
    "    line=line.strip()\n",
    "    #splitting the lines into the words suing the split function\n",
    "    words= line.split()\n",
    "    for word in words:\n",
    "        #converting all the words to lowercase as not to duplicate if the starting letter of the word is a capital.\n",
    "        word= word.lower()\n",
    "        #counting the occurancies of the word and add them to the count dictionary.\n",
    "        #using the word as the key we can pull the record of word from the count dictionary using the get function.\n",
    "        count[word]=count.get(word,0)+1\n",
    "        #if the word is not present already then the exp \"count.get(word,0)\" will return 0 and then starts counting from 1.\n",
    "        #If the word ias already present then it returns the number of times the word has been counted and this step adds 1 to it.\n",
    "    return count\n",
    "def reducefunction(past_count, new_count):\n",
    "    #iterating the mapped count and add the count from the present word count.\n",
    "    for word,count in new_count.items():\n",
    "        #using the word as the key we can pull the record of word from the count dictionary iusing the get function.\n",
    "        past_count[word]=past_count.get(word,0)+count\n",
    "        #if the word is not present already then the exp \"count.get(word,0)\" will return 0 and then starts counting from 1.\n",
    "        #If the word ias already present then it returns the number of times the word has been counted and this step adds 1\n",
    "    return past_count\n",
    "if __name__ == \"__main__\":\n",
    "    # Accessing the file using the file path and saving it as the file1_path variable\n",
    "    file1_path= \"file1.txt\"\n",
    "    wordcounts=mapreduce(file1_path)\n",
    "    #Sorted() function sorts the key value pairs of the passed dictionary \n",
    "    #using the for loop for iteration through the key-value pairs of the Alphabetically sorted dictionary \n",
    "    for word,count in sorted(wordcounts.items()):\n",
    "        #printing the word and its count using the formatted string method\n",
    "        print(f\"{word}:{count}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ba432",
   "metadata": {},
   "source": [
    "# number of times non-English words were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb193aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Birth year is 2000. So choosing the pages 100-109 in the book\n",
    "#created the .txt file using the above conditions as file2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d931fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62: 1\n",
      "63: 1\n",
      "64: 1\n",
      "65: 1\n",
      "66: 1\n",
      "67: 1\n",
      "68: 1\n",
      "?”: 1\n",
      "able,: 1\n",
      "adventure.”: 1\n",
      "again,: 2\n",
      "again.: 1\n",
      "again.”: 2\n",
      "all?”: 1\n",
      "and,: 1\n",
      "apparate: 2\n",
      "apparated: 1\n",
      "apparators.: 1\n",
      "are,: 1\n",
      "ask.: 1\n",
      "attack,”: 1\n",
      "auror: 1\n",
      "babberton.”: 1\n",
      "before;: 1\n",
      "began,: 1\n",
      "benches.: 1\n",
      "bidding.: 1\n",
      "black;: 1\n",
      "bones.”: 1\n",
      "breathe,: 1\n",
      "brightly.: 1\n",
      "brooms.: 1\n",
      "budleigh: 1\n",
      "cage,: 1\n",
      "calmly.: 1\n",
      "can’t: 1\n",
      "case,: 1\n",
      "certainly.: 1\n",
      "chest;: 1\n",
      "church,: 1\n",
      "clear.”: 1\n",
      "colleague’s: 1\n",
      "complaining,”: 1\n",
      "cool,: 1\n",
      "cornelius.”: 1\n",
      "corner,: 1\n",
      "corpses,”: 1\n",
      "couldn’t: 1\n",
      "counterjinx: 1\n",
      "course,: 3\n",
      "course.: 1\n",
      "dark.: 1\n",
      "darkness.: 1\n",
      "dementors,: 1\n",
      "didn’t: 1\n",
      "directions;: 1\n",
      "do,: 1\n",
      "do,”: 1\n",
      "don’t: 1\n",
      "door,”: 1\n",
      "drive.: 1\n",
      "dumbledore: 14\n",
      "dumbledore,: 5\n",
      "dumbledore.: 8\n",
      "dumbledore’s: 3\n",
      "ears,: 1\n",
      "eater,: 1\n",
      "eaters.: 1\n",
      "else,: 1\n",
      "embarrassment;: 1\n",
      "enjoying.: 1\n",
      "entry.: 1\n",
      "established,: 1\n",
      "expression.: 1\n",
      "eyes.: 1\n",
      "face-to-face: 1\n",
      "fine,”: 1\n",
      "forearm.: 1\n",
      "garden.: 1\n",
      "gate,: 1\n",
      "go.”: 1\n",
      "good,”: 1\n",
      "good?”: 1\n",
      "granger: 1\n",
      "grip;: 1\n",
      "grounds,”: 1\n",
      "hand,: 1\n",
      "hand.: 1\n",
      "harry,: 7\n",
      "harry,”: 2\n",
      "harry.: 3\n",
      "harry.”: 2\n",
      "harry’s: 1\n",
      "haven’t: 1\n",
      "head;: 1\n",
      "hedwig: 1\n",
      "here,: 2\n",
      "here.: 1\n",
      "here?”: 1\n",
      "he’s: 1\n",
      "him,: 1\n",
      "him.: 1\n",
      "hogwarts: 1\n",
      "hogwarts,: 1\n",
      "hogwarts.”: 1\n",
      "house?”: 1\n",
      "houses.: 2\n",
      "however,: 3\n",
      "impostor.”: 1\n",
      "inferi: 2\n",
      "inferi.: 1\n",
      "instance,: 1\n",
      "it.: 1\n",
      "i’m: 2\n",
      "i’ve: 1\n",
      "j.k.: 7\n",
      "jam,: 1\n",
      "justice.”: 1\n",
      "knew,: 1\n",
      "late,: 1\n",
      "leaflet,: 1\n",
      "left,: 1\n",
      "life,: 1\n",
      "life.: 1\n",
      "lightning-shaped: 1\n",
      "loss.: 1\n",
      "lungfuls: 1\n",
      "mark.: 1\n",
      "me,: 2\n",
      "me,”: 1\n",
      "me.”: 1\n",
      "meant.: 1\n",
      "midnight.: 1\n",
      "mind.: 1\n",
      "moment.”: 1\n",
      "myself,”: 1\n",
      "myself.”: 1\n",
      "neck,: 1\n",
      "not,: 2\n",
      "not.: 2\n",
      "noticed,: 1\n",
      "now,: 1\n",
      "now,”: 1\n",
      "occasion,: 1\n",
      "occlumency: 1\n",
      "office.”: 1\n",
      "otherwise,”: 1\n",
      "ouch.”: 1\n",
      "owl,: 1\n",
      "pace,: 1\n",
      "place,: 1\n",
      "pocket.: 1\n",
      "possessions.: 1\n",
      "powerful.: 1\n",
      "question,”: 1\n",
      "questions.: 1\n",
      "quickly.: 1\n",
      "quietly.: 1\n",
      "ready,: 1\n",
      "really.”: 1\n",
      "reference,: 1\n",
      "relaxed.: 1\n",
      "reluctantly.: 1\n",
      "replaced,: 1\n",
      "reported,: 1\n",
      "right,”: 1\n",
      "right.: 1\n",
      "right?”: 1\n",
      "rowling: 7\n",
      "rufus: 2\n",
      "sacked.: 1\n",
      "said,: 2\n",
      "said.: 1\n",
      "saw,: 1\n",
      "school,: 1\n",
      "scrimgeour: 1\n",
      "scrimgeour,: 1\n",
      "senses,: 1\n",
      "seventeen?”: 1\n",
      "shelter.: 1\n",
      "short.: 1\n",
      "simply.: 1\n",
      "sir?”: 3\n",
      "slughorn: 1\n",
      "small,: 1\n",
      "smiled,: 1\n",
      "smiling.: 1\n",
      "snubbed,: 1\n",
      "solicitously.: 1\n",
      "square,: 1\n",
      "steep,: 1\n",
      "street.: 1\n",
      "subject,: 1\n",
      "tale,: 1\n",
      "temptress,: 1\n",
      "test,”: 1\n",
      "that,: 1\n",
      "that.: 1\n",
      "them,: 1\n",
      "them.: 2\n",
      "they?: 1\n",
      "tightly.: 1\n",
      "time,: 1\n",
      "to.”: 1\n",
      "together.: 1\n",
      "tonight.”: 1\n",
      "too,: 1\n",
      "too.: 1\n",
      "trunk,: 1\n",
      "tube.: 1\n",
      "useful?”: 1\n",
      "vaguely.: 1\n",
      "vanished.: 2\n",
      "voldemort: 2\n",
      "voldemort.”: 1\n",
      "voldemort’s: 2\n",
      "waited,: 1\n",
      "wasn’t: 1\n",
      "way.”: 1\n",
      "we?”: 1\n",
      "we’ll: 1\n",
      "witch.: 1\n",
      "wizarding: 1\n",
      "wizard’s: 1\n",
      "www.ztcprep.com: 10\n",
      "years,: 1\n",
      "yes,: 1\n",
      "you,”: 2\n",
      "you.: 1\n",
      "you.”: 1\n",
      "|: 7\n",
      "–: 7\n",
      "—: 6\n",
      "—”: 2\n",
      "“a: 1\n",
      "“ah: 1\n",
      "“an: 1\n",
      "“and: 5\n",
      "“are: 1\n",
      "“because: 1\n",
      "“but: 2\n",
      "“correct,”: 1\n",
      "“courtesy: 1\n",
      "“dead: 1\n",
      "“did: 1\n",
      "“er: 2\n",
      "“for: 1\n",
      "“harry?”: 1\n",
      "“he: 2\n",
      "“hermione: 1\n",
      "“how: 1\n",
      "“i: 5\n",
      "“i,: 1\n",
      "“if: 1\n",
      "“is: 1\n",
      "“it: 1\n",
      "“i’m: 1\n",
      "“keep: 1\n",
      "“left: 1\n",
      "“lord: 1\n",
      "“no,: 1\n",
      "“no,”: 2\n",
      "“not: 1\n",
      "“oh,: 1\n",
      "“professor,: 2\n",
      "“professor?”: 1\n",
      "“sir: 1\n",
      "“sir,: 1\n",
      "“so: 2\n",
      "“the: 1\n",
      "“they: 1\n",
      "“this: 2\n",
      "“this,: 1\n",
      "“very: 1\n",
      "“well,: 4\n",
      "“why: 1\n",
      "“yes,: 2\n",
      "“yes,”: 1\n",
      "“you: 3\n",
      "“your: 1\n",
      "“—: 1\n",
      "…: 7\n",
      "…”: 5\n"
     ]
    }
   ],
   "source": [
    "#defining a function to load the english words from the file downloaded from the website \"http://www.gwicks.net/dictionaries.htm\"\n",
    "def load_english_words(file_path):\n",
    "    #defining a set to store the words from the document\n",
    "    eng_words = set()\n",
    "    #using the open function we are opening the file in the readable format\n",
    "    with open(file_path, 'r', encoding='utf-8') as engfile:\n",
    "        #iterating through the file line by line\n",
    "        for line in engfile:\n",
    "            #removing the white spaces at the beginning and end of the lines using the strip function.\n",
    "            # we are not using the split function because each line contains one word in the file\n",
    "            word= line.strip()\n",
    "            #converting all the words to lowercase as not to duplicate if the starting letter of the word is a capital.\n",
    "            #adding the words to the set using the add function\n",
    "            eng_words.add(word.lower())  \n",
    "            #returning the set\n",
    "    return eng_words\n",
    "#defining the function \n",
    "def non_english_words(file_path, eng_words):\n",
    "    #defining a dictionary to store the non english words and its count\n",
    "    non_eng = {}\n",
    "    #using the open function we are opening the file in the readable format\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        \n",
    "        for line in file:\n",
    "            #removing the white spaces at the beginning and end of the lines using the strip function.\n",
    "            line = line.strip()\n",
    "            #splitting the lines into the words using the split function\n",
    "            words=line.split()\n",
    "            for word in words:\n",
    "                #converting all the words to lowercase as not to duplicate if the starting letter of the word is a capital.\n",
    "                word=word.lower()\n",
    "                # Check if the word is present in the passed set'eng_words'\n",
    "                if word not in eng_words:\n",
    "                    #counting the occurancies of the word and add them to the dictionary.\n",
    "                    #using the word as the key we can pull the record of word from the dictionary using the get function.\n",
    "                    non_eng[word] = non_eng.get(word, 0) + 1\n",
    "    #returning the non english word count dioctionary            \n",
    "    return non_eng\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # calling the function load_english_words and passing the filepath to it.\n",
    "    eng_words = load_english_words(\"usa.txt\")\n",
    "    # Accessing the file using the file path and saving it as the file2_path variable\n",
    "    file_path = \"file2.txt\"\n",
    "    #saving the result of the function. to the dictionarey\n",
    "    #calling the function and passing the file path and the engwords set to it.\n",
    "    non_english_word_counts = non_english_words(file_path, eng_words)\n",
    "    #using the for loop for iteration through the key-value pairs of the dictionary \n",
    "    for word, count in sorted(non_english_word_counts.items()):\n",
    "         #printing the word and its count using the formatted string method\n",
    "        print(f\"{word}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
